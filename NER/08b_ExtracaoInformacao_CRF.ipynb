{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08b_ExtracaoInformacao_CRF.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NBKYahII-iyZ"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valmirf/mineracao_textual/blob/main/NER/08b_ExtracaoInformacao_CRF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kcv9r63uIesu"
      },
      "source": [
        "!git clone https://github.com/valmirf/mineracao_textual.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMPzRXpm-e9_"
      },
      "source": [
        "# Extraindo Entidades Nomeadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNYnsDfJlfwu"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCExIfejlk6r"
      },
      "source": [
        "# Lendo arquivo de entrada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1PZezIlljsD"
      },
      "source": [
        "df = pd.read_csv('mineracao_textual/Dados/ner_dataset.csv', encoding = \"ISO-8859-1\")\n",
        "df = df[:10000] #apenas para processar mais rápido\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ7ZuX4Dl6Ob"
      },
      "source": [
        "Exsitem 457 sentenças contendo 2.746 palavras diferentes e 17 tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu4FdRCNl2Uq"
      },
      "source": [
        "df = df.fillna(method='ffill')\n",
        "df['Sentence #'].nunique(), df.Word.nunique(), df.Tag.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke7GqN_vmGCF"
      },
      "source": [
        "df.groupby('Tag').size().reset_index(name='counts')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vy-n6HLdmMii"
      },
      "source": [
        "# Transformando dados para vetor e criando treino/teste -> para algoritmos tradicionais!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuY_ZGP_mQfy"
      },
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop('Tag', axis=1) #elimina o rótulo\n",
        "v = DictVectorizer(sparse=False) #mapeia palavras para índices\n",
        "X = v.fit_transform(X.to_dict('records'))\n",
        "y = df.Tag.values\n",
        "\n",
        "classes = np.unique(y)\n",
        "classes = classes.tolist()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=0)\n",
        "X_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHn3KCmfXLfd"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdUNOTvtm8hz"
      },
      "source": [
        "# CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owC1hM0um93t"
      },
      "source": [
        "!pip install sklearn_crfsuite\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKLrJQrVnQfD"
      },
      "source": [
        "Função para recuperar sentenças com os POS e as tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCw5JHPxnLj0"
      },
      "source": [
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(), \n",
        "                                                           s['POS'].values.tolist(), \n",
        "                                                           s['Tag'].values.tolist())]\n",
        "        self.grouped = self.data.groupby('Sentence #').apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "        \n",
        "    def get_next(self):\n",
        "        try: \n",
        "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s \n",
        "        except:\n",
        "            return None\n",
        "getter = SentenceGetter(df)\n",
        "sentences = getter.sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGKGwC6anaNc"
      },
      "source": [
        "# Criando o formato de entrada do CRF (extração de características)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-LufvFBnfnj"
      },
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "    \n",
        "    features = {\n",
        "        'bias': 1.0, \n",
        "        'word.lower()': word.lower(), \n",
        "        'word[-3:]': word[-3:],\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word.isupper()': word.isupper(),\n",
        "        'word.istitle()': word.istitle(),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "        'postag': postag,\n",
        "        'postag[:2]': postag[:2],\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        features.update({\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.istitle()': word1.istitle(),\n",
        "            '-1:word.isupper()': word1.isupper(),\n",
        "            '-1:postag': postag1,\n",
        "            '-1:postag[:2]': postag1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][1]\n",
        "        features.update({\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word.istitle()': word1.istitle(),\n",
        "            '+1:word.isupper()': word1.isupper(),\n",
        "            '+1:postag': postag1,\n",
        "            '+1:postag[:2]': postag1[:2],\n",
        "        })\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "    return features\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, postag, label in sent]\n",
        "    \n",
        "def sent2tokens(sent):\n",
        "    return [token for token, postag, label in sent]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnnZKGNUnsic"
      },
      "source": [
        "# Divisão de treinamento e teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o1lUeG2nrrl"
      },
      "source": [
        "X = [sent2features(s) for s in sentences]\n",
        "y = [sent2labels(s) for s in sentences]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVknFX41qQMG"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi4pNAEt0KtE"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUAShk8rnzJl"
      },
      "source": [
        "# Treinando o modelo CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7OLEdRznw12"
      },
      "source": [
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm='lbfgs',\n",
        "    c1=0.1,\n",
        "    c2=0.1,\n",
        "    max_iterations=100,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "crf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FHeTEEmoAZ8"
      },
      "source": [
        "# Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkNt8dFjn_66"
      },
      "source": [
        "y_pred = crf.predict(X_test)\n",
        "print('Resultados com todas as classes')\n",
        "print(metrics.flat_classification_report(y_test, y_pred))\n",
        "print('--------------------------------------------------------------------')\n",
        "print('Resultados eliminando a classe O')\n",
        "print(metrics.flat_classification_report(y_test, y_pred, labels=['B-art','B-eve','B-geo','B-gpe','B-nat','B-org','B-per','B-tim','I-art','I-eve','I-geo','I-gpe','I-nat','I-org','I-per','I-tim'], target_names=['B-art','B-eve','B-geo','B-gpe','B-nat','B-org','B-per','B-tim','I-art','I-eve','I-geo','I-gpe','I-nat','I-org','I-per','I-tim']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdWYLn-GoRvr"
      },
      "source": [
        "# Entendendo o funcionamento do algoritmo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJBHubNdoUZc"
      },
      "source": [
        "def print_transitions(trans_features):\n",
        "    for (label_from, label_to), weight in trans_features:\n",
        "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
        "\n",
        "print(\"Top-20 transições mais prováveis:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
        "\n",
        "print(\"Top-20 transições menos prováveis:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr3xhUD9orik"
      },
      "source": [
        "def print_state_features(state_features):\n",
        "    for (attr, label), weight in state_features:\n",
        "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
        "\n",
        "print(\"Top-20 positivo:\")\n",
        "print_state_features(Counter(crf.state_features_).most_common(20))\n",
        "\n",
        "print(\"Top-20 negativo:\")\n",
        "print_state_features(Counter(crf.state_features_).most_common()[-20:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlhV3rnSo8Z8"
      },
      "source": [
        "!pip install eli5\n",
        "import eli5\n",
        "eli5.show_weights(crf, top=10)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}