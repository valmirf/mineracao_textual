{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08a_ExtracaoInformacao.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NBKYahII-iyZ"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valmirf/mineracao_textual/blob/main/NER/06a_ExtracaoInformacao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMPzRXpm-e9_"
      },
      "source": [
        "# Extraindo Entidades Nomeadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkNdurX0G6z-"
      },
      "source": [
        "## SpaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8hbyepxG87A"
      },
      "source": [
        "import spacy\n",
        "from spacy import displacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cetMeEw-LtKv"
      },
      "source": [
        "### Modelos pré-treinados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffdMmdHfHnL9"
      },
      "source": [
        "'''BAIXANDO O MODELO DA LÍNGUA PORTUGUESA'''\n",
        "!python -m spacy download pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMkOesVjHqYA"
      },
      "source": [
        "'''CLASSIFICANDO CONTEÚDO ATRAVÉS DO MODELO'''\n",
        "\n",
        "text = 'Donald Trump, portador do cpf 064.468.404-62, chegou aos EUA no dia 01/06/2019. Donald Trump visitou Barack Obama e George Bush. Além disso, ele esteve em diversos estados do país pilotando uma ferrari.'\n",
        "\n",
        "my_model = spacy.load('pt') #carrega o modelo\n",
        "document = my_model(text) #carrega o documento\n",
        "\n",
        "print('Original Sentence: %s\\n\\n' % (text))\n",
        "    \n",
        "displacy.render(document, jupyter=True, style='ent') #vai extrair as entidades. Pode usar outras opções, como POS, ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQMtoHjVHzlT"
      },
      "source": [
        "### Criando seu próprio modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhZcuWZkHx7w"
      },
      "source": [
        "import random\n",
        "def train_spacy(data,iterations, base_model=None):\n",
        "    TRAIN_DATA = data\n",
        "    #caso tenha um modelo como base\n",
        "    if base_model:\n",
        "      nlp = spacy.load(base_model)\n",
        "      print(\"Loaded model '%s'\" % nlp)\n",
        "    else:\n",
        "      nlp = spacy.blank('pt')      \n",
        "      print('Created blank model')\n",
        "\n",
        "    if \"ner\" not in nlp.pipe_names:\n",
        "        ner = nlp.create_pipe(\"ner\")\n",
        "        nlp.add_pipe(ner, last=True)\n",
        "    # otherwise, get it so we can add labels\n",
        "    else:\n",
        "        print('ner......')\n",
        "        ner = nlp.get_pipe(\"ner\")\n",
        "        \n",
        "    # add labels\n",
        "    for _, annotations in TRAIN_DATA:\n",
        "         for ent in annotations.get('entities'):\n",
        "            ner.add_label(ent[2])\n",
        "    \n",
        "    # get names of other pipes to disable them during training\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "        optimizer = nlp.begin_training()\n",
        "        for itn in range(iterations):\n",
        "            random.shuffle(TRAIN_DATA)\n",
        "            losses = {}\n",
        "            for text, annotations in TRAIN_DATA:\n",
        "                nlp.update(\n",
        "                    [text],         # batch of texts\n",
        "                    [annotations],  # batch of annotations\n",
        "                    drop=0.2,       # dropout - make it harder to memorise data\n",
        "                    sgd=optimizer,  # callable to update weights\n",
        "                    losses=losses)\n",
        "    return nlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfVgVPTgIAIv"
      },
      "source": [
        "TRAIN_DATA = [('Em 15/07/1988 nasceu essa linda criança', {'entities': [(3, 13, 'Data')]}), \n",
        "              ('Rafael Mello, portador do cpf 064.468.404-62, chegou aos EUA', {'entities': [(0, 12, 'Pessoa'),(30, 44, 'CPF')]}),\n",
        "              ('Data de prisão: 10/01/2018', {'entities': [(16, 26, 'Data')]}),\n",
        "              ('No dia 01/02/2016 foi decretada a setença', {'entities': [(7, 17, 'Data')]}),\n",
        "              ('A data da festa foi 07/05/2019', {'entities': [(20, 30, 'Data')]}),\n",
        "              ('João, portador do cpf 123.456.789-65, foi encontrado', {'entities': [(0, 4, 'PER'), (18, 32, 'CPF')]}),\n",
        "              ('O cpf 025.412.876-99 pertence a Maria', {'entities': [(6, 20, 'CPF')]})\n",
        "             ]\n",
        "#Formato - Sentença, {Entidade :[(Índice Inicial do Token, Índice Final do Token, Tipo)]} \n",
        "\n",
        "my_model = train_spacy(TRAIN_DATA, 20)\n",
        "document = my_model(text)\n",
        "\n",
        "print('Original Sentence: %s\\n' % (text))\n",
        "displacy.render(document, jupyter=True, style='ent')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc3_Pah_J2kx"
      },
      "source": [
        "Se você estiver usando um modelo existente, certifique-se de misturar exemplos de outros tipos de entidade que o spaCy reconheceu corretamente antes. Caso contrário, seu modelo pode aprender o novo tipo, mas “esquecer” o que ele sabia anteriormente. Isso também é conhecido como o problema do “esquecimento catastrófico”."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL3oUyLGIxh3"
      },
      "source": [
        "my_model2 = train_spacy(TRAIN_DATA, 20, 'pt')\n",
        "document = my_model2(text)\n",
        "\n",
        "print('Original Sentence: %s\\n' % (text))\n",
        "displacy.render(document, jupyter=True, style='ent')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJKQ7-JSa2Tr"
      },
      "source": [
        "## Adicionando padrões (dicionário)\n",
        "\n",
        "O SpaCy permite que você defina seu próprio dicionário, utilizando ou não funções linguísticas (https://spacy.io/usage/rule-based-matching)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CeM7bDSXH6u"
      },
      "source": [
        "from spacy.matcher import Matcher\n",
        "from spacy.tokens import Span\n",
        "\n",
        "matcher = Matcher(my_model.vocab)\n",
        "matcher.add(\"CARRO\", None, [{\"LOWER\": \"ferrari\"}])\n",
        "\n",
        "doc = my_model(text)\n",
        "matches = matcher(doc)\n",
        "\n",
        "for match_id, start, end in matches:\n",
        "    # create a new Span for each match and use the match_id (ANIMAL) as the label\n",
        "    span = Span(doc, start, end, label=match_id)\n",
        "    doc.ents = list(doc.ents) + [span]  # add span to doc.ents\n",
        "\n",
        "displacy.render(doc, jupyter=True, style='ent')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBKYahII-iyZ"
      },
      "source": [
        "## FLAIR\n",
        "Utilizaremos inicialmente o Flair Framework para nossa tarefa de NER. É uma biblioteca que implementa o estado da arte em NLP atualmente, além de permitir o uso de modelos pré-treinados de forma bastante prática e simples. Ele utiliza o Pytorch como base para definição da sua arquitetura de redes neurais. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DshxgyXC_CmY"
      },
      "source": [
        "### Instalando"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "resp3mIq-Kxh"
      },
      "source": [
        "!pip install flair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_JngOzK_KNU"
      },
      "source": [
        "### Testando"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc2ujFQj_GjQ"
      },
      "source": [
        "#import commands for flair NER\n",
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqDHejdf_OzW"
      },
      "source": [
        "### Modelos Pré-treinados (EN)\n",
        "\n",
        "Você pode ver a lista completa de modelos pré-treinados aqui: https://github.com/flairNLP/flair "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCgfsJgm_I_N"
      },
      "source": [
        "#Load NER Model\n",
        "tagger = SequenceTagger.load('ner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNEovWge_ZRX"
      },
      "source": [
        "#Sample text to run NER\n",
        "text = 'Jackson is placed in Microsoft located in Redmond'\n",
        "\n",
        "#passing text to sentence\n",
        "sentence = Sentence(text)\n",
        "\n",
        "# Run NER on sentence to identify Entities\n",
        "tagger.predict(sentence)\n",
        "\n",
        "# print the entities with below command\n",
        "for entity in sentence.get_spans('ner'):\n",
        "    print(entity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vXmE4AN_kk8"
      },
      "source": [
        "print(sentence.to_tagged_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY_HOuRZ_t9n"
      },
      "source": [
        "Testando outra sentença"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JpcbX4r_rCw"
      },
      "source": [
        "#Sample text\n",
        "text1 = 'Redmond is coming to New York city'\n",
        "\n",
        "#passing text to sentence\n",
        "sentence = Sentence(text1)\n",
        "\n",
        "# Run NER on sentence to identify Entities\n",
        "tagger.predict(sentence)\n",
        "\n",
        "# print the entities with below command\n",
        "for entity in sentence.get_spans('ner'):\n",
        "    print(entity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEWpul3aum0Y"
      },
      "source": [
        "print(sentence.to_tagged_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aspDysTn_7dd"
      },
      "source": [
        "### Treinando modelo FLAIR em Portugues\n",
        "\n",
        "O treinamento de modelos do FLAIR é bem custoso, e normalmente obtém melhores resultados utilizando embeddings pré-treinados associados a embeddings específicos para fases forward e backward do algoritmo. \n",
        "\n",
        "Até o momento não existem modelos prétreinados disponíveis diretamente no framework, mas algumas iniciativas já estão em andamento (https://github.com/jneto04/ner-pt)"
      ]
    }
  ]
}