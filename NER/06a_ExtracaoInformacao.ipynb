{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08a_ExtracaoInformacao.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NBKYahII-iyZ"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valmirf/mineracao_textual/blob/main/NER/06a_ExtracaoInformacao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkNdurX0G6z-"
      },
      "source": [
        "## Named entity recognition (NER) <a id='ner'></a>\n",
        "\n",
        "Named entity recognition (NER) é uma das principais tarefas em projetos de recuperação e extração de informação em textos. Muitas tarefas se iniciam a partir da detecção de entidades nomeadas, como a extração de relações por exemplo. \n",
        "\n",
        "Em NER, as diferentes entidades nomeadas extraídas são agrupadas por tipo. Por exemplo, \"pessoa\", \"organização\", \"local\", \"país\" etc. No spaCy, existem muitos [tipos diferentes](https://spacy.io/api/annotation#named-entities) de entidades nomeadas que ele pode extrair com modelos pré-treinados.\n",
        "\n",
        "As entidades nomeadas no spaCy estão disponíveis como propriedade `ents` de um` Doc`. O `.label_` nos diz o tipo de entidade nomeada."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#instalando bibliotecas\n",
        "!pip install spacy\n",
        "!spacy download pt"
      ],
      "metadata": {
        "id": "k2doDEEclyqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "b2qdurb6l1Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('pt')\n",
        "doc = nlp(\"Eu estarei em Recife próxima semana. Será que levo roupa para frio?\")\n",
        "for ent in doc.ents:\n",
        "    print(ent.text,ent.label_)"
      ],
      "metadata": {
        "id": "Nd5vnAdkk63z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Geraldo Júlio é o prefeito de Recife.\")\n",
        "for ent in doc.ents:\n",
        "    print(ent.text,ent.label_)"
      ],
      "metadata": {
        "id": "LviXBFNZk8zY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#explain também funciona para entidades\n",
        "spacy.explain('LOC')"
      ],
      "metadata": {
        "id": "ykKIEnaVk-bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício 1\n",
        "\n",
        "Extraia todas as entidades nomeadas da variável `review`."
      ],
      "metadata": {
        "id": "pjZ0cyizlDNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto\n",
        "review = '''Este é sem dúvida o pior filme que eu já vi. E acredite em mim, eu vi muitos filmes. A reviravolta inacreditável que o filme faz - passando de um extremamente mau filme \"Formas de vida alienígenas habitam a terra\", com um filme que tenta espalhar um arquicristiano \"O dia do julgamento está próximo, buscar Jesus ou queimar por toda a eternidade em as dívidas ardentes do inferno \"mensagem - deixou-me atordoado depois de ter sido atormentado por 85 minutos. Até mesmo os cristãos religiosos devem se envergonhar ou ficar furiosos ao ver suas crenças postadas dessa maneira. Eu não sabia o que fazer comigo quando assisti a atuação horrível que poderia ter sido realizada por crianças de 7 anos de idade. Simplesmente repugnante. Eu não sou cristão nem muito religioso. Mas se eu estivesse, não teria mais medo do Inferno. Rich Christiano mostrou ser algo muito pior.'''\n",
        "\n",
        "doc = nlp(review)\n",
        "for ent in doc.ents:\n",
        "    print(ent.text,' - ',ent.label_,' - ',spacy.explain(ent.label_))"
      ],
      "metadata": {
        "id": "pERjBi7DlC4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício 2\n",
        "Utilizar a lib do python `wikipedia`, para baixar o conteúdo da página referente ao cantor Luiz Gonzaga no wikipedia em português, e analise quais as entidades presentes nas 10 primeiras sentenças do texto."
      ],
      "metadata": {
        "id": "-B52IjhFlISH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "id": "1E_9t0MGlNJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wikipedia\n",
        "wikipedia.set_lang(\"pt\")\n",
        "p = wikipedia.page(\"Luiz Gonzaga\")\n",
        "\n",
        "print(p.url)\n",
        "print(p.title)\n",
        "\n",
        "content = p.content "
      ],
      "metadata": {
        "id": "QxYA1ZyWlPBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sua resposta\n",
        "doc = nlp(content)\n",
        "for sent in list(doc.sents)[0:10]:\n",
        "  for ent in sent.ents:\n",
        "        print(ent.text,' - ',ent.label_,' - ',spacy.explain(ent.label_))\n",
        "  print()"
      ],
      "metadata": {
        "id": "gfWRMsjBlRdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualização NER <a id='visualize-ner'></a>\n",
        "\n",
        "O displaCy é uma extensão do spaCy para visualização do processo de PLN. \n",
        "\n",
        "Após importar a lib `displacy`, podemos usar o método `render` sobre o `doc` criado."
      ],
      "metadata": {
        "id": "vJ9FcJ1_lUbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy"
      ],
      "metadata": {
        "id": "9YL4Lq0XlX80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(review)\n",
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "metadata": {
        "id": "FbMfXgd1lcrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício\n",
        "\n",
        "Utilize o `displacy` para visualizar as entidades encontradas em algumas das sentenças do conteúdo da página do wikipedia analisada no exercício anterior."
      ],
      "metadata": {
        "id": "-bwg2zx8lUid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sua resposta"
      ],
      "metadata": {
        "id": "8RomiE4zljux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMPzRXpm-e9_"
      },
      "source": [
        "# Extraindo Entidades Nomeadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8hbyepxG87A"
      },
      "source": [
        "import spacy\n",
        "from spacy import displacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cetMeEw-LtKv"
      },
      "source": [
        "### Modelos pré-treinados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffdMmdHfHnL9"
      },
      "source": [
        "'''BAIXANDO O MODELO DA LÍNGUA PORTUGUESA'''\n",
        "!python -m spacy download pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMkOesVjHqYA"
      },
      "source": [
        "'''CLASSIFICANDO CONTEÚDO ATRAVÉS DO MODELO'''\n",
        "\n",
        "text = 'Donald Trump, portador do cpf 064.468.404-62, chegou aos EUA no dia 01/06/2019. Donald Trump visitou Barack Obama e George Bush. Além disso, ele esteve em diversos estados do país pilotando uma ferrari.'\n",
        "\n",
        "my_model = spacy.load('pt') #carrega o modelo\n",
        "document = my_model(text) #carrega o documento\n",
        "\n",
        "print('Original Sentence: %s\\n\\n' % (text))\n",
        "    \n",
        "displacy.render(document, jupyter=True, style='ent') #vai extrair as entidades. Pode usar outras opções, como POS, ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQMtoHjVHzlT"
      },
      "source": [
        "### Criando seu próprio modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhZcuWZkHx7w"
      },
      "source": [
        "import random\n",
        "def train_spacy(data,iterations, base_model=None):\n",
        "    TRAIN_DATA = data\n",
        "    #caso tenha um modelo como base\n",
        "    if base_model:\n",
        "      nlp = spacy.load(base_model)\n",
        "      print(\"Loaded model '%s'\" % nlp)\n",
        "    else:\n",
        "      nlp = spacy.blank('pt')      \n",
        "      print('Created blank model')\n",
        "\n",
        "    if \"ner\" not in nlp.pipe_names:\n",
        "        ner = nlp.create_pipe(\"ner\")\n",
        "        nlp.add_pipe(ner, last=True)\n",
        "    # otherwise, get it so we can add labels\n",
        "    else:\n",
        "        print('ner......')\n",
        "        ner = nlp.get_pipe(\"ner\")\n",
        "        \n",
        "    # add labels\n",
        "    for _, annotations in TRAIN_DATA:\n",
        "         for ent in annotations.get('entities'):\n",
        "            ner.add_label(ent[2])\n",
        "    \n",
        "    # get names of other pipes to disable them during training\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "        optimizer = nlp.begin_training()\n",
        "        for itn in range(iterations):\n",
        "            random.shuffle(TRAIN_DATA)\n",
        "            losses = {}\n",
        "            for text, annotations in TRAIN_DATA:\n",
        "                nlp.update(\n",
        "                    [text],         # batch of texts\n",
        "                    [annotations],  # batch of annotations\n",
        "                    drop=0.2,       # dropout - make it harder to memorise data\n",
        "                    sgd=optimizer,  # callable to update weights\n",
        "                    losses=losses)\n",
        "    return nlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfVgVPTgIAIv"
      },
      "source": [
        "TRAIN_DATA = [('Em 15/07/1988 nasceu essa linda criança', {'entities': [(3, 13, 'Data')]}), \n",
        "              ('Rafael Mello, portador do cpf 064.468.404-62, chegou aos EUA', {'entities': [(0, 12, 'Pessoa'),(30, 44, 'CPF')]}),\n",
        "              ('Data de prisão: 10/01/2018', {'entities': [(16, 26, 'Data')]}),\n",
        "              ('No dia 01/02/2016 foi decretada a setença', {'entities': [(7, 17, 'Data')]}),\n",
        "              ('A data da festa foi 07/05/2019', {'entities': [(20, 30, 'Data')]}),\n",
        "              ('João, portador do cpf 123.456.789-65, foi encontrado', {'entities': [(0, 4, 'PER'), (18, 32, 'CPF')]}),\n",
        "              ('O cpf 025.412.876-99 pertence a Maria', {'entities': [(6, 20, 'CPF')]})\n",
        "             ]\n",
        "#Formato - Sentença, {Entidade :[(Índice Inicial do Token, Índice Final do Token, Tipo)]} \n",
        "\n",
        "my_model = train_spacy(TRAIN_DATA, 20)\n",
        "document = my_model(text)\n",
        "\n",
        "print('Original Sentence: %s\\n' % (text))\n",
        "displacy.render(document, jupyter=True, style='ent')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc3_Pah_J2kx"
      },
      "source": [
        "Se você estiver usando um modelo existente, certifique-se de misturar exemplos de outros tipos de entidade que o spaCy reconheceu corretamente antes. Caso contrário, seu modelo pode aprender o novo tipo, mas “esquecer” o que ele sabia anteriormente. Isso também é conhecido como o problema do “esquecimento catastrófico”."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL3oUyLGIxh3"
      },
      "source": [
        "my_model2 = train_spacy(TRAIN_DATA, 20, 'pt')\n",
        "document = my_model2(text)\n",
        "\n",
        "print('Original Sentence: %s\\n' % (text))\n",
        "displacy.render(document, jupyter=True, style='ent')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJKQ7-JSa2Tr"
      },
      "source": [
        "## Adicionando padrões (dicionário)\n",
        "\n",
        "O SpaCy permite que você defina seu próprio dicionário, utilizando ou não funções linguísticas (https://spacy.io/usage/rule-based-matching)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CeM7bDSXH6u"
      },
      "source": [
        "from spacy.matcher import Matcher\n",
        "from spacy.tokens import Span\n",
        "\n",
        "matcher = Matcher(my_model.vocab)\n",
        "matcher.add(\"CARRO\", None, [{\"LOWER\": \"ferrari\"}])\n",
        "\n",
        "doc = my_model(text)\n",
        "matches = matcher(doc)\n",
        "\n",
        "for match_id, start, end in matches:\n",
        "    # create a new Span for each match and use the match_id (ANIMAL) as the label\n",
        "    span = Span(doc, start, end, label=match_id)\n",
        "    doc.ents = list(doc.ents) + [span]  # add span to doc.ents\n",
        "\n",
        "displacy.render(doc, jupyter=True, style='ent')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBKYahII-iyZ"
      },
      "source": [
        "## FLAIR\n",
        "Utilizaremos inicialmente o Flair Framework (https://github.com/flairNLP/flair) para nossa tarefa de NER. É uma biblioteca que implementa o estado da arte em NLP atualmente, além de permitir o uso de modelos pré-treinados de forma bastante prática e simples. Ele utiliza o Pytorch como base para definição da sua arquitetura de redes neurais. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DshxgyXC_CmY"
      },
      "source": [
        "### Instalando"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "resp3mIq-Kxh"
      },
      "source": [
        "!pip install flair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_JngOzK_KNU"
      },
      "source": [
        "### Testando"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc2ujFQj_GjQ"
      },
      "source": [
        "#import commands for flair NER\n",
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqDHejdf_OzW"
      },
      "source": [
        "### Modelos Pré-treinados (EN)\n",
        "\n",
        "Você pode ver a lista completa de modelos pré-treinados aqui: https://github.com/flairNLP/flair "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCgfsJgm_I_N"
      },
      "source": [
        "#Load NER Model\n",
        "tagger = SequenceTagger.load('ner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNEovWge_ZRX"
      },
      "source": [
        "#Sample text to run NER\n",
        "text = 'Jackson is placed in Microsoft located in Redmond'\n",
        "\n",
        "#passing text to sentence\n",
        "sentence = Sentence(text)\n",
        "\n",
        "# Run NER on sentence to identify Entities\n",
        "tagger.predict(sentence)\n",
        "\n",
        "# print the entities with below command\n",
        "for entity in sentence.get_spans('ner'):\n",
        "    print(entity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vXmE4AN_kk8"
      },
      "source": [
        "print(sentence.to_tagged_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY_HOuRZ_t9n"
      },
      "source": [
        "Testando outra sentença"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JpcbX4r_rCw"
      },
      "source": [
        "#Sample text\n",
        "text1 = 'Redmond is coming to New York city'\n",
        "\n",
        "#passing text to sentence\n",
        "sentence = Sentence(text1)\n",
        "\n",
        "# Run NER on sentence to identify Entities\n",
        "tagger.predict(sentence)\n",
        "\n",
        "# print the entities with below command\n",
        "for entity in sentence.get_spans('ner'):\n",
        "    print(entity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEWpul3aum0Y"
      },
      "source": [
        "print(sentence.to_tagged_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aspDysTn_7dd"
      },
      "source": [
        "### Treinando modelo FLAIR em Portugues\n",
        "\n",
        "O treinamento de modelos do FLAIR é bem custoso, e normalmente obtém melhores resultados utilizando embeddings pré-treinados associados a embeddings específicos para fases forward e backward do algoritmo. \n",
        "\n",
        "Até o momento não existem modelos prétreinados disponíveis diretamente no framework, mas algumas iniciativas já estão em andamento (https://github.com/jneto04/ner-pt)"
      ]
    }
  ]
}