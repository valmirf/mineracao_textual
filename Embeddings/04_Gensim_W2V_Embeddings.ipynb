{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_Gensim_W2V_Embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valmirf/mineracao_textual/blob/main/Embeddings/04_Gensim_W2V_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtkkVXY3z_wY"
      },
      "source": [
        "# Treinando uma representação de Embeddings de texto com Gensim\n",
        "\n",
        "O [Word2vec](https://en.wikipedia.org/wiki/Word2vec) é uma técnica muito popular de Processamento de Linguagem Natural que usa uma rede neural para aprender as representações vetoriais de palavras chamadas \"embeddings\" em um texto específico.\n",
        "\n",
        "Neste tutorial, usaremos a excelente implementação do word2vec do pacote [gensim](https://radimrehurek.com/gensim/index.html) para criar nosso modelo word2vec. Usaremos o método de redução de dimensionalidade PCA no sklearn para visualizar os vetores de embeddings aprendidos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0EeYiui0txC"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "import multiprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYbRd85eFWpY"
      },
      "source": [
        "**Corpus**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC1qG0Am17pW"
      },
      "source": [
        "sentences = [\n",
        "      ['van', 'gogh', 'nasceu', 'numa', 'família', 'de', 'classe', 'média', 'alta'],\n",
        "      ['começou', 'a', 'desenhar', 'ainda', 'criança', 'sendo', 'descrito', 'como', 'alguém', 'sério', ',', 'quieto', 'e', 'pensativo'],\n",
        "      ['vincent', 'willem', 'van', 'gogh', 'gostava', 'de', 'desenhar', 'em', 'zundert'],\n",
        "      ['vincent', 'era', 'um', 'nome', 'comum', 'na', 'família', 'van', 'gogh'],\n",
        "      ['era', 'o', 'filho', 'mais', 'velho', 'sobrevivente', 'de', 'anna', 'cornelia', 'carbentus', 'e', 'theodorus', '.']\n",
        "      \n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb_jOaERFZeb"
      },
      "source": [
        "## Treinando o Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBtVutmA1_Km"
      },
      "source": [
        "model = Word2Vec(sentences,\n",
        "                 sg=1, #0 para CBOW\n",
        "                 size=300,\n",
        "                 workers=multiprocessing.cpu_count(),\n",
        "                 iter=5,\n",
        "                 negative=5,\n",
        "                 min_count=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf7Hj1oqJGUx"
      },
      "source": [
        "**Vetor da palavra \"vincent\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh_VBUstJFqA"
      },
      "source": [
        "print(len(model[\"vincent\"]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN5zjQ9nG1IS"
      },
      "source": [
        "**Armazenando todos vetores do Modelo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpXOm2w1GoJ9"
      },
      "source": [
        "x = model[model.wv.vocab]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeRgTbgAHY23"
      },
      "source": [
        "## Visualização\n",
        "**Redução da Dimensionalidade**\n",
        "\n",
        "Reduz a dimensionalidade para 2 dimensões pra apresetação no gráfico abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFxE4VEhHJDs"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "dim = pca.fit_transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpPlzF2PKATa"
      },
      "source": [
        "**Plot do Modelo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTBESLSxHv5e"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.scatter(dim[:, 0], dim[:, 1])\n",
        "\n",
        "words = list(model.wv.vocab)\n",
        "for i, word in enumerate(words):\n",
        "\tplt.annotate(word, xy=(dim[i, 0], dim[i, 1]))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nxZltY5Fj4w"
      },
      "source": [
        "**Salvando os embeddings gerados**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLVWSVaG2TtP"
      },
      "source": [
        "model.save('model.bin')\n",
        "\n",
        "model.wv.save_word2vec_format(\"model_skpg_300d.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSuTBYegFof5"
      },
      "source": [
        "**Carregando Modelo .bin**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTCTGzBO2YDu"
      },
      "source": [
        "model_bin = Word2Vec.load('model.bin')\n",
        "\n",
        "model_bin['gogh'][0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9-nJS_KIxvA"
      },
      "source": [
        "**Carregando Modelo .txt**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWXRsHNPItfU"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "model_txt = KeyedVectors.load_word2vec_format('model_skpg_300d.txt')\n",
        "\n",
        "model_txt['gogh'][0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__OocQBx_loq"
      },
      "source": [
        "model_txt.most_similar('vincent')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0NQ2-9nED9I"
      },
      "source": [
        "## Visualizando no tensorboard\n",
        "\n",
        "Execute a celula abaixo, e carregue os arquivos gerados no http://projector.tensorflow.org/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjPTYqquDMgw"
      },
      "source": [
        "import io\n",
        "\n",
        "# Vector file, `\\t` seperated the vectors and `\\n` seperate the words\n",
        "\"\"\"\n",
        "0.1\\t0.2\\t0.5\\t0.9\n",
        "0.2\\t0.1\\t5.0\\t0.2\n",
        "0.4\\t0.1\\t7.0\\t0.8\n",
        "\"\"\"\n",
        "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "# Meta data file, `\\n` seperated word\n",
        "\"\"\"\n",
        "token1\n",
        "token2\n",
        "token3\n",
        "\"\"\"\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "# Write meta file and vector file\n",
        "for index in range(len(model_txt.index2word)):\n",
        "    word = model_txt.index2word[index]\n",
        "    vec = model_txt.vectors[index]\n",
        "    out_m.write(word + \"\\n\")\n",
        "    out_v.write(''.join([str(x) for x in vec]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Zky8ewHdJ0k"
      },
      "source": [
        "# Exemplo: Embeddings de textos de Machado de Assis\n",
        "Vamos utilizar o Word2Vec para produzir uma representação vetorial e visualização das palavras de textos de um corpus do livro de Memórias Póstumas de Brás Cubas, no corpus do NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6FRtWFddV3x"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('mac_morpho') \n",
        "nltk.download('floresta')\n",
        "\n",
        "#from nltk.corpus import machado\n",
        "\n",
        "#print(str(machado))\n",
        "\n",
        "\n",
        "from __future__ import print_function, unicode_literals\n",
        "\n",
        "from nltk.corpus import machado, mac_morpho, floresta, genesis\n",
        "from nltk.text import Text\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.util import bigrams\n",
        "from nltk.misc import babelize_shell\n",
        "\n",
        "print(mac_morpho.readme())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49-RykqzQLyE"
      },
      "source": [
        "nltk.download(\"mac_morpho\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OukKXNZd4wG"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from nltk.corpus import machado\n",
        "import unicodedata\n",
        "\n",
        "# Remove acentos e coloca palavras em minúsculas\n",
        "def strip_accents_and_lower(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn').lower()\n",
        "\n",
        "mac_morpho_sents = map(lambda sent: list(map(strip_accents_and_lower, sent)), mac_morpho.sents())\n",
        "\n",
        "# 'Executa' o mapeamento da lista\n",
        "%time mac_morpho_sents = list(mac_morpho_sents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8v14G7Sgfb0"
      },
      "source": [
        "Utilize as sentenças da variável `machado_sents` para treinar e visualizar o embedding produzido"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF5abpxPd9aw"
      },
      "source": [
        "model_mac_morpho = Word2Vec(mac_morpho_sents,\n",
        "                 sg=1, #0 para CBOW\n",
        "                 size=300,\n",
        "                 workers=multiprocessing.cpu_count(),\n",
        "                 iter=5,\n",
        "                 negative=5,\n",
        "                 min_count=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB22bK3NgxYS"
      },
      "source": [
        "Exiba as palavras mais próximas da lista abaixo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCDllE-ug1kf"
      },
      "source": [
        "# Exibe algumas palavras próximas daquelas contidas nesta lista\n",
        "test_words = ['seja', 'foi', 'jornal', 'noticia', 'foram', 'homem', 'bairro']\n",
        "\n",
        "# Embedding de uma palavra\n",
        "def word_embedding(word):\n",
        "    return model_mac_morpho.wv[word]\n",
        "\n",
        "# Pega apenas as palavras a partir do resultado da função 'most_similar'\n",
        "def strip_score(result):\n",
        "    return [w for w, s in result]\n",
        "    \n",
        "# Lista as palavras mais próximas\n",
        "def closest_words(word, num=5):\n",
        "    word_score_pair = model_mac_morpho.wv.most_similar(word, topn=num)\n",
        "    return strip_score(word_score_pair)\n",
        "\n",
        "for w in test_words:\n",
        "    print(w, closest_words(w))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}